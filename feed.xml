<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://dltemple.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://dltemple.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-24T18:59:50+00:00</updated><id>https://dltemple.github.io/feed.xml</id><title type="html">DWGHT</title><subtitle></subtitle><entry><title type="html">A Comprehensive Study Guide for Deep Learning Engineer Interviews at NVIDIA</title><link href="https://dltemple.github.io/thoughts/2023/nvidia-deep-learning-engineer/" rel="alternate" type="text/html" title="A Comprehensive Study Guide for Deep Learning Engineer Interviews at NVIDIA"/><published>2023-05-01T00:00:00+00:00</published><updated>2023-05-01T00:00:00+00:00</updated><id>https://dltemple.github.io/thoughts/2023/nvidia-deep-learning-engineer</id><content type="html" xml:base="https://dltemple.github.io/thoughts/2023/nvidia-deep-learning-engineer/"><![CDATA[<h1 id="a-comprehensive-study-guide-for-deep-learning-engineer-interviews-at-nvidia">A Comprehensive Study Guide for Deep Learning Engineer Interviews at NVIDIA</h1> <p><strong>Unlock the doors</strong> to an unparalleled opportunity at NVIDIA, the vanguard of cutting-edge <strong>GPU technology</strong> and <strong>AI innovation</strong>. Are you a passionate deep learning engineer ready to make your mark in the AI realm? üåü This comprehensive guide is tailored just for you. Learn from the wisdom of industry experts, gain insights into <strong>NVIDIA‚Äôs culture</strong>, and prepare for an interview that could transform your career. Let‚Äôs embark on a journey to <strong>mastery and success</strong> in the world of deep learning, together. üöÄ</p> <h2 id="1-fundamentals-of-deep-learning">1. Fundamentals of Deep Learning</h2> <h3 id="a-artificial-neural-networks">a. Artificial Neural Networks</h3> <p>Immerse yourself in the mesmerizing world of artificial neural networks (ANNs) as an NVIDIA deep learning engineer. You‚Äôll harness the power and elegance of these computing systems, inspired by the intricate biological neural networks within the human brain. üß† ANNs consist of a delicate tapestry of interconnected nodes (neurons), gracefully woven into layers: input, hidden, and output layers.</p> <p>‚ú® <strong>Key concepts</strong> to enrich your deep learning journey at NVIDIA include:</p> <p><strong>Feedforward networks</strong>: The foundational architecture where information travels seamlessly in one direction, from input to output, unraveling complex patterns in data.</p> <p><strong>Convolutional Neural Networks (CNNs)</strong>: Delve into the realm of image and video processing with CNNs, designed to capture spatial patterns and transform them into a rich tapestry of features.</p> <p><strong>Recurrent Neural Networks (RNNs)</strong>: Embrace the power of RNNs to model sequential data, where connections form a temporal loop, allowing the network to store and retrieve information from the past, creating a dynamic memory.</p> <p><strong>Transformer networks</strong>: Revolutionize your understanding of natural language processing and beyond with the transformative architecture of Transformer networks, harnessing the strength of self-attention mechanisms and parallel processing to conquer even the most intricate of tasks.</p> <p>Embark on this remarkable adventure as a deep learning engineer at NVIDIA, and let these powerful concepts guide you in shaping the future of AI innovation. üåü</p> <h3 id="b-activation-functions">b. Activation Functions</h3> <p><strong>Let‚Äôs dive</strong> into the <em>enticing complexity</em> of activation functions, shall we? These functions inject a dose of non-linearity into the network, endowing it with the remarkable ability to learn those ever-so-intricate patterns. At NVIDIA, you‚Äôll find yourself mingling with some of the most <em>captivating</em> activation functions:</p> <ul> <li><strong>Sigmoid</strong>: A smooth character, elegantly mapping input values to a delightful range between 0 and 1.</li> <li><strong>Hyperbolic tangent (tanh)</strong>: The suave sibling of Sigmoid, taking things up a notch by mapping inputs to a range from -1 to 1.</li> <li><strong>Rectified Linear Unit (ReLU)</strong>: The no-nonsense, straight-to-the-point operator, keeping things positive by setting negative inputs to zero.</li> <li><strong>Leaky ReLU</strong>: ReLU‚Äôs slightly mischievous cousin, allowing a tiny bit of negative input to slip through with a small, non-zero slope.</li> <li><strong>Softmax</strong>: The charming diplomat, gracefully converting raw scores into probabilities that sum up to 1, perfect for multi-class classification problems.</li> <li><strong>Exponential Linear Unit (ELU)</strong>: The adventurous type, bringing exponential dynamics to the table, aiming to mitigate the vanishing gradient problem.</li> <li><strong>Swish</strong>: A modern and flexible player, using the self-gated mechanism to adaptively balance the input and output signals.</li> </ul> <p>Let‚Äôs <em>delve deeper</em> into the <strong>pros and cons</strong> of these beguiling activation functions, and when to invite them to the neural network party:</p> <ul> <li><strong>Sigmoid</strong>: <ul> <li><em>Pros</em>: Smooth and differentiable, providing clear probabilities for binary classification problems.</li> <li><em>Cons</em>: Prone to vanishing gradient problem; not zero-centered; computationally expensive.</li> <li><em>Best used</em>: When the output layer requires probabilities for binary classification.</li> </ul> </li> <li><strong>Hyperbolic tangent (tanh)</strong>: <ul> <li><em>Pros</em>: Zero-centered and smoother than Sigmoid; suitable for a wider range of input values.</li> <li><em>Cons</em>: Still susceptible to the vanishing gradient problem; computationally expensive.</li> <li><em>Best used</em>: When the output layer requires values between -1 and 1; in hidden layers for some cases.</li> </ul> </li> <li><strong>Rectified Linear Unit (ReLU)</strong>: <ul> <li><em>Pros</em>: Computationally efficient; helps mitigate vanishing gradient problem; encourages sparse activation.</li> <li><em>Cons</em>: Inactive for negative inputs, causing the ‚Äúdying ReLU‚Äù problem; not zero-centered.</li> <li><em>Best used</em>: In hidden layers of deep networks due to its computational efficiency.</li> </ul> </li> <li><strong>Leaky ReLU</strong>: <ul> <li><em>Pros</em>: Addresses the ‚Äúdying ReLU‚Äù issue by allowing small negative values; computationally efficient.</li> <li><em>Cons</em>: May cause instability in some cases; not zero-centered.</li> <li><em>Best used</em>: In hidden layers where the ‚Äúdying ReLU‚Äù problem is a concern.</li> </ul> </li> <li><strong>Softmax</strong>: <ul> <li><em>Pros</em>: Provides probabilities for multi-class classification problems; smooth and differentiable.</li> <li><em>Cons</em>: Computationally expensive; not suitable for hidden layers.</li> <li><em>Best used</em>: In the output layer for multi-class classification problems.</li> </ul> </li> <li><strong>Exponential Linear Unit (ELU)</strong>: <ul> <li><em>Pros</em>: Aims to mitigate vanishing gradient problem; encourages smooth and nonzero output for negative inputs.</li> <li><em>Cons</em>: Computationally expensive due to the exponential function.</li> <li><em>Best used</em>: In hidden layers where vanishing gradient is a concern and computational resources are sufficient.</li> </ul> </li> <li><strong>Swish</strong>: <ul> <li><em>Pros</em>: Self-gated mechanism allows adaptability; smooth and differentiable; potential to outperform ReLU.</li> <li><em>Cons</em>: Computationally expensive due to the additional multiplication operation.</li> <li><em>Best used</em>: In hidden layers where adaptability and potential performance improvement are desired, and computational resources are sufficient.</li> </ul> </li> </ul> <p>Let these enchanting activation functions <em>guide you</em> through the intricate world of deep learning, and <em>choose wisely</em> according to the specific needs of your dashing neural network designs. Embrace the <em>allure</em> of their strengths and dance around their weaknesses, as you set forth on your journey as an NVIDIA deep learning engineer.</p> <h3 id="c-loss-functions">c. Loss Functions</h3> <p>Loss functions, my friend, <em>quantify</em> the difference between the predicted output and the actual target. As a <em>deep learning engineer</em>, you‚Äôll need to choose the appropriate loss function for the task at hand. Let‚Äôs dive into some common loss functions and their pros, cons, and usage scenarios:</p> <ol> <li><strong>Mean Squared Error (MSE)</strong>: <ul> <li><em>Pros</em>: Simple to compute and differentiable</li> <li><em>Cons</em>: Can be sensitive to outliers</li> <li><em>When to use</em>: Regression tasks</li> <li><em>When to avoid</em>: Classification tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{MSE}(y, \hat{y}) = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2 \end{aligned}\)</li> </ul> </li> <li><strong>Cross-Entropy</strong>: <ul> <li><em>Pros</em>: Effective for multi-class classification, focuses on probabilities</li> <li><em>Cons</em>: Not suitable for regression tasks</li> <li><em>When to use</em>: Classification tasks, particularly multi-class classification</li> <li><em>When to avoid</em>: Regression tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Cross-Entropy}(y, \hat{y}) = -\sum_{i=1}^{n}y_i \log(\hat{y}_i) \end{aligned}\)</li> </ul> </li> <li><strong>Hinge loss</strong>: <ul> <li><em>Pros</em>: Encourages large margins between classes, suitable for Support Vector Machines (SVMs)</li> <li><em>Cons</em>: Not suitable for non-binary classification or regression tasks</li> <li><em>When to use</em>: Binary classification with SVMs</li> <li><em>When to avoid</em>: Multi-class classification, regression tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Hinge Loss}(y, \hat{y}) = \sum_{i=1}^{n}\max(0, 1 - y_i\hat{y}_i) \end{aligned}\)</li> </ul> </li> <li><strong>Huber loss</strong>: <ul> <li><em>Pros</em>: Combines benefits of MSE and Mean Absolute Error (MAE), robust to outliers</li> <li><em>Cons</em>: Requires tuning of hyperparameter delta</li> <li><em>When to use</em>: Regression tasks with outliers</li> <li><em>When to avoid</em>: Classification tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Huber Loss}(y, \hat{y}, \delta) = \begin{cases} \frac{1}{2}(y - \hat{y})^2 &amp; \text{for } |y - \hat{y}| \le \delta \\ \delta (|y - \hat{y}| - \frac{1}{2}\delta) &amp; \text{otherwise} \end{cases} \end{aligned}\)</li> </ul> </li> </ol> <p>And now, let‚Äôs explore some more exotic loss function types:</p> <ol> <li><strong>Log-Cosh loss</strong>: <ul> <li><em>Pros</em>: Smoother than MSE, less sensitive to outliers</li> <li><em>Cons</em>: Computationally more expensive than MSE</li> <li><em>When to use</em>: Regression tasks with noisy data</li> <li><em>When to avoid</em>: Classification tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Log-Cosh Loss}(y, \hat{y}) = \sum_{i=1}^{n}\log(\cosh(\hat{y}_i - y_i)) \end{aligned}\)</li> </ul> </li> <li><strong>Kullback-Leibler Divergence (KLD)</strong>: <ul> <li><em>Pros</em>: Measures the difference between two probability distributions, suitable for unsupervised learning</li> <li><em>Cons</em>: Computationally expensive</li> <li><em>When to use</em>: Unsupervised learning, comparing distributions</li> <li><em>When to avoid</em>: Simple regression or classification tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{KLD}(P, Q) = \sum_{i}P(i)\log\left(\frac{P(i)}{Q(i)}\right) \end{aligned}\)</li> </ul> </li> <li><strong>Poisson loss</strong>: <ul> <li><em>Pros</em>: Suitable for count-based regression tasks</li> <li><em>Cons</em>: Assumes data follows a Poisson distribution, not suitable for classification tasks</li> <li><em>When to use</em>: Count-based regression tasks (e.g., predicting the number of events)</li> <li><em>When to avoid</em>: Classification tasks, non-count-based regression tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Poisson Loss}(y, \hat{y}) = \sum_{i=1}^{n}(\hat{y}_i - y_i\log(\hat{y}_i)) \end{aligned}\)</li> </ul> </li> <li><strong>Dice loss</strong>: <ul> <li><em>Pros</em>: Effective for segmentation tasks, balances precision and recall</li> <li><em>Cons</em>: Not suitable for regression tasks, can be sensitive to class imbalance</li> <li><em>When to use</em>: Image segmentation tasks, especially in medical imaging</li> <li><em>When to avoid</em>: Regression tasks, simple classification tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Dice Loss}(y, \hat{y}) = 1 - \frac{2\sum_{i=1}^{n}y_i\hat{y}_i}{\sum_{i=1}^{n}y_i^2 + \sum_{i=1}^{n}\hat{y}_i^2} \end{aligned}\)</li> </ul> </li> <li><strong>Cosine similarity loss</strong>: <ul> <li><em>Pros</em>: Measures the angle between two vectors, invariant to scale</li> <li><em>Cons</em>: Not suitable for traditional classification or regression tasks</li> <li><em>When to use</em>: Comparing embeddings or high-dimensional vectors (e.g., in recommendation systems)</li> <li><em>When to avoid</em>: Simple regression or classification tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Cosine Similarity Loss}(A, B) = 1 - \frac{\sum_{i=1}^{n}A_iB_i}{\sqrt{\sum_ {i=1}^{n}A_i^2}\sqrt{\sum_{i=1}^{n}B_i^2}} \end{aligned}\)</li> </ul> </li> <li><strong>Triplet loss</strong>: <ul> <li><em>Pros</em>: Effective for learning embeddings in a relative space, useful for tasks such as face recognition</li> <li><em>Cons</em>: Requires careful selection of triplets, not suitable for traditional classification or regression tasks</li> <li><em>When to use</em>: Learning embeddings for tasks like face recognition or image retrieval</li> <li><em>When to avoid</em>: Simple regression or classification tasks</li> <li><em>Function</em>: \(\begin{aligned} \text{Triplet Loss}(a, p, n) = \max(0, ||a - p||_2^2 - ||a - n||_2^2 + \alpha) \end{aligned}\)</li> </ul> </li> </ol> <p>By understanding the characteristics of each loss function, you‚Äôll be well-equipped to select the most appropriate one for your deep learning tasks at NVIDIA. Good luck, and don‚Äôt forget to enjoy the journey!</p> <h3 id="d-optimizers">d. Optimizers</h3> <p>Optimizers are algorithms used to update the model‚Äôs weights and minimize the loss function. Key optimizers that you may use as an NVIDIA deep learning engineer include:</p> <ul> <li>Stochastic Gradient Descent (SGD)</li> <li>Momentum</li> <li>Nesterov Accelerated Gradient (NAG)</li> <li>AdaGrad</li> <li>RMSprop</li> <li>Adam</li> </ul> <h3 id="e-regularization-techniques">e. Regularization Techniques</h3> <p>Regularization techniques help prevent overfitting and improve generalization. Techniques you may apply at NVIDIA include:</p> <ul> <li>L1 and L2 regularization</li> <li>Dropout</li> <li>Early stopping</li> <li>Batch normalization</li> <li>Data augmentation</li> </ul> <h3 id="f-forward-and-backpropagation">f. Forward and Backpropagation</h3> <p>Forward propagation is the process of calculating the output of the neural network given an input. Backpropagation is an algorithm used to minimize the loss function by calculating the gradients of the loss with respect to each weight and updating the weights accordingly.</p> <h3 id="g-gradient-descent-and-its-variants">g. Gradient Descent and its Variants</h3> <p>Gradient descent is an optimization algorithm used to minimize the loss function by iteratively updating the model‚Äôs weights. As an NVIDIA deep learning engineer, you‚Äôll work with various gradient descent variants:</p> <ul> <li>Batch Gradient Descent</li> <li>Stochastic Gradient Descent (SGD)</li> <li>Mini-batch Gradient Descent</li> </ul> <h2 id="2-popular-deep-learning-architectures">2. Popular Deep Learning Architectures</h2> <ul> <li>Convolutional Neural Networks (CNNs)</li> <li>Recurrent Neural Networks (RNNs) <ul> <li>Long Short-Term Memory (LSTM)</li> <li>Gated Recurrent Units (GRU)</li> </ul> </li> <li>Autoencoders and Variational Autoencoders</li> <li>Generative Adversarial Networks (GANs)</li> <li>Transformer models (e.g., BERT, GPT)</li> </ul> <h2 id="3-frameworks-and-libraries">3. Frameworks and Libraries</h2> <h3 id="a-tensorflow">a. TensorFlow</h3> <p>TensorFlow is an open-source deep learning library developed by Google Brain. It‚Äôs widely used for various machine learning and deep learning tasks, including neural networks, reinforcement learning, and natural language processing. TensorFlow is known for its flexible architecture, allowing you to deploy computation on multiple platforms ((e.g., CPUs, GPUs, and TPUs). Key features include:</p> <ul> <li>Tensor: The core data structure, which represents n-dimensional arrays.</li> <li>Eager execution: Allows you to run operations immediately without building a computation graph first, making it easier to debug.</li> <li>TensorFlow Lite: A lightweight version for deploying models on mobile and edge devices.</li> <li>TensorFlow Extended (TFX): An end-to-end platform for deploying production machine learning pipelines.</li> </ul> <h3 id="b-pytorch">b. PyTorch</h3> <p>PyTorch is an open-source deep learning library developed by Facebook‚Äôs AI Research lab (FAIR). It‚Äôs known for its dynamic computation graph and ease of use, making it popular among researchers and developers. Key features include:</p> <ul> <li>Dynamic computation graph: Allows you to build and modify computation graphs on-the-fly, which can be helpful for debugging and prototyping.</li> <li>TorchScript: A way to convert PyTorch models into a format that can be optimized and run independently of Python, making it easier to deploy.</li> <li>Distributed training: Support for parallel and distributed training of models, which can speed up training and improve scalability.</li> <li>PyTorch Lightning: A lightweight wrapper around PyTorch that simplifies training, evaluation, and model deployment.</li> </ul> <h3 id="c-keras">c. Keras</h3> <p>Keras is a high-level neural networks API, originally developed as a user-friendly API for building deep learning models. It can run on top of TensorFlow, Microsoft Cognitive Toolkit, or Theano. In recent years, Keras has been integrated into TensorFlow as the official high-level API, known as <code class="language-plaintext highlighter-rouge">tf.keras</code>. Key features include:</p> <ul> <li>Modularity: Consists of building blocks (layers, optimizers, activation functions) that can be combined to create custom models.</li> <li>Preprocessing: Provides built-in data preprocessing functions for images, text, and sequences.</li> <li>Pre-trained models: Offers a collection of pre-trained models for common tasks like image classification, object detection, and more.</li> <li>Model callbacks: Allows you to monitor and respond to model training events, such as saving the best model, early stopping, or adjusting learning rates.</li> </ul> <h3 id="d-cuda-and-cudnn-nvidia-specific-tools">d. CUDA and cuDNN (NVIDIA-specific tools)</h3> <p>CUDA (Compute Unified Device Architecture) is a parallel computing platform and programming model developed by NVIDIA. It allows developers to use NVIDIA GPUs for general-purpose computing tasks. cuDNN (CUDA Deep Neural Network library) is a GPU-accelerated library for deep learning built on top of CUDA. These tools are essential for optimizing deep learning performance on NVIDIA GPUs. Key features include:</p> <ul> <li>GPU-accelerated operations: Provides GPU-optimized implementations of various operations, such as convolutions, pooling, and activation functions.</li> <li>Cross-platform compatibility: Supports multiple GPU architectures and works with various deep learning frameworks, like TensorFlow and PyTorch.</li> <li>Tensor Cores: Specialized hardware components available in some NVIDIA GPUs that accelerate mixed-precision matrix operations, resulting in faster training and inference.</li> <li>NVIDIA Nsight: A suite of debugging and profiling tools for GPU-accelerated applications, helping developers identify performance bottlenecks and optimize their code.</li> </ul> <h2 id="4-preprocessing-and-data-augmentation-techniques">4. Preprocessing and Data Augmentation Techniques</h2> <ul> <li>Image preprocessing</li> <li>Text preprocessing</li> <li>Time-series data preprocessing</li> <li>Data augmentation methods</li> </ul> <h2 id="5-model-evaluation-and-hyperparameter-tuning">5. Model Evaluation and Hyperparameter Tuning</h2> <ul> <li>Metrics for classification, regression, and generative models</li> <li>Cross-validation techniques</li> <li>Hyperparameter tuning methods (e.g., grid search, random search, Bayesian optimization)</li> </ul> <h2 id="6-deployment-and-optimization">6. Deployment and Optimization</h2> <h3 id="a-model-deployment-strategies">a. Model Deployment Strategies</h3> <ul> <li> <p>Cloud: Cloud-based deployment involves deploying your deep learning models on remote servers managed by a cloud service provider (e.g., AWS, Google Cloud, Microsoft Azure). This approach allows for easy scalability, reduced infrastructure costs, and faster deployment. Cloud deployment often uses containerization technologies like Docker and orchestration tools like Kubernetes for managing and scaling services.</p> </li> <li> <p>Edge devices: Edge deployment involves deploying models on devices that are physically close to the data source, such as IoT devices, smartphones, or local servers. This approach enables real-time processing, reduced latency, and increased privacy. However, edge deployment may have limited computational resources and may require model optimization to run efficiently on the device.</p> </li> <li> <p>On-premises: On-premises deployment involves deploying models on local servers or data centers within the organization‚Äôs infrastructure. This approach provides better control over data security and compliance but may require significant upfront investment in hardware and maintenance.</p> </li> </ul> <h3 id="b-model-optimization-techniques">b. Model Optimization Techniques</h3> <ul> <li> <p>Quantization: Quantization is the process of reducing the numerical precision of model weights and activations, usually from 32-bit floating-point numbers to lower-precision formats like 16-bit or 8-bit integers. This reduces model size and speeds up computation while maintaining acceptable levels of accuracy.</p> </li> <li> <p>Pruning: Pruning involves removing less important connections or neurons in a neural network, thereby reducing the number of parameters and computational complexity. Various pruning techniques exist, including weight pruning, neuron pruning, and structured pruning (e.g., pruning entire filters in CNNs).</p> </li> <li> <p>Distillation: Knowledge distillation is a technique where a smaller, more efficient student model is trained to mimic the behavior of a larger, more accurate teacher model. The student model learns from the teacher model‚Äôs output, usually through a softened version of the teacher model‚Äôs logits, which helps the student model generalize better and achieve higher accuracy.</p> </li> </ul> <h3 id="c-nvidia-tensorrt">c. NVIDIA TensorRT</h3> <p>NVIDIA TensorRT is a high-performance deep learning inference optimizer and runtime library designed to optimize and deploy deep learning models on NVIDIA GPUs. TensorRT supports multiple deep learning frameworks, such as TensorFlow and PyTorch. Key features of TensorRT include:</p> <ul> <li> <p>Layer and Tensor Fusion: TensorRT fuses multiple layers and tensors in the neural network to form a single, optimized layer. This reduces memory access overhead and improves inference speed.</p> </li> <li> <p>Kernel Auto-Tuning: TensorRT selects the best CUDA kernels for the target GPU and automatically tunes the kernel parameters for optimal performance.</p> </li> <li> <p>Dynamic Tensor Memory: TensorRT optimizes memory usage during inference by reusing memory allocated for intermediate tensors.</p> </li> <li> <p>Precision Calibration: TensorRT supports mixed-precision optimization, allowing you to use lower-precision data types (e.g., FP16, INT8) while maintaining model accuracy through calibration. This reduces memory usage and speeds up inference.</p> </li> </ul> <h2 id="7-domain-specific-deep-learning-applications">7. Domain-specific Deep Learning Applications</h2> <ul> <li>Computer vision</li> <li>Natural language processing</li> <li>Speech recognition and synthesis</li> <li>Reinforcement learning</li> <li>Generative models</li> </ul> <h2 id="8-research-trends-and-recent-advancements">8. Research Trends and Recent Advancements</h2> <ul> <li>Keep up-to-date with the latest deep learning research and advancements</li> <li>Read papers, blogs, and attend conferences/webinars if possible</li> </ul> <h2 id="9-soft-skills-and-behavioral-questions">9. Soft Skills and Behavioral Questions</h2> <h3 id="a-collaboration-and-teamwork">a. Collaboration and Teamwork</h3> <p><strong>Question:</strong> ‚ÄúCan you describe a time when you had to collaborate with a difficult team member?‚Äù<br/> <strong>Answer:</strong></p> <ul> <li><em>Situation:</em> ‚ÄúDuring a previous project, I had to work with a team member who had a different working style and often disagreed with the rest of the team.‚Äù</li> <li><em>Task:</em> ‚ÄúMy goal was to ensure that the project was completed on time and to maintain a positive team atmosphere.‚Äù</li> <li><em>Action:</em> ‚ÄúI arranged a one-on-one meeting with the team member to understand their concerns and find common ground. We openly discussed our differences, and I suggested ways we could collaborate more effectively, such as dividing tasks based on our strengths.‚Äù</li> <li><em>Result:</em> ‚ÄúAs a result, we were able to work together more efficiently, and the project was completed on time. Our communication improved, and the team dynamic became more positive.‚Äù</li> </ul> <h3 id="b-communication">b. Communication</h3> <p><strong>Question:</strong> ‚ÄúHow do you handle explaining complex technical concepts to non-technical stakeholders?‚Äù<br/> <strong>Answer:</strong></p> <ul> <li><em>Situation:</em> ‚ÄúIn my previous role, I frequently had to present machine learning models and their results to non-technical executives.‚Äù</li> <li><em>Task:</em> ‚ÄúMy objective was to ensure they understood the model‚Äôs purpose, its benefits, and the impact on the business.‚Äù</li> <li><em>Action:</em> ‚ÄúI focused on simplifying the technical aspects by using analogies and visual aids, while emphasizing the practical implications of the model. I also prepared for questions by anticipating areas of confusion and practicing concise explanations.‚Äù</li> <li><em>Result:</em> ‚ÄúThe stakeholders were able to grasp the key concepts and make informed decisions based on my presentations. This led to a higher level of trust and collaboration between the technical and non-technical teams.‚Äù</li> </ul> <h3 id="c-problem-solving">c. Problem-solving</h3> <p><strong>Question:</strong> ‚ÄúDescribe a situation where you faced a challenging problem, and how you resolved it.‚Äù<br/> <strong>Answer:</strong></p> <ul> <li><em>Situation:</em> ‚ÄúWhile working on a fraud detection project, I encountered an issue with the model‚Äôs performance, which wasn‚Äôt meeting the desired accuracy threshold.‚Äù</li> <li><em>Task:</em> ‚ÄúMy goal was to identify the root cause of the problem and improve the model‚Äôs accuracy.‚Äù</li> <li><em>Action:</em> ‚ÄúI started by analyzing the dataset, verifying the preprocessing steps, and reviewing the model architecture. I discovered that the dataset was imbalanced, causing the model to be biased towards the majority class. I implemented a combination of under-sampling, over-sampling, and adjusting class weights to address the issue.‚Äù</li> <li><em>Result:</em> ‚ÄúAfter applying these changes, the model‚Äôs accuracy significantly improved, and it successfully detected fraud cases with higher precision and recall.‚Äù</li> </ul> <h3 id="d-time-management">d. Time Management</h3> <p><strong>Question:</strong> ‚ÄúHow do you prioritize tasks when faced with multiple deadlines?‚Äù<br/> <strong>Answer:</strong></p> <ul> <li><em>Situation:</em> ‚ÄúIn my previous job, there were times when I had to manage multiple projects with overlapping deadlines.‚Äù</li> <li><em>Task:</em> ‚ÄúMy objective was to efficiently allocate my time and resources to ensure all projects were completed on schedule.‚Äù</li> <li><em>Action:</em> ‚ÄúI used a combination of time management techniques, such as creating a prioritized to-do list, breaking tasks into smaller milestones, and setting realistic deadlines. I also communicated my workload to my team and manager to ensure transparency and to seek help when needed.‚Äù</li> <li><em>Result:</em> ‚ÄúBy effectively prioritizing and managing my time, I was able to complete all projects on schedule while maintaining a high level of quality.‚Äù</li> </ul> <h3 id="e-adaptability">e. Adaptability</h3> <p><strong>Question:</strong> ‚ÄúTell me about a time when you had to adapt to a significant change at work.‚Äù<br/> <strong>Answer:</strong></p> <ul> <li><em>Situation:</em> ‚ÄúAt my previous job, our team had to switch from using TensorFlow to PyTorch for a new project, while still maintaining our existing TensorFlow-based projects.‚Äù</li> <li><em>Task:</em> ‚ÄúMy goal was to quickly adapt to the new framework and ensure a smooth transition for the team.‚Äù</li> <li><em>Action:</em> ‚ÄúI proactively took online courses and read documentation to familiarize myself with PyTorch. I also participated in code reviews and discussions with colleagues experienced in PyTorch to gain practical insights. To facilitate the team‚Äôs transition, I created a guide highlighting the key differences between the two frameworks and conducted training sessions to share my knowledge.‚Äù</li> <li><em>Result:</em> ‚ÄúAs a result, the team was able to adapt to the new framework more quickly and efficiently. We successfully developed and maintained projects in both TensorFlow and PyTorch, demonstrating our adaptability and ability to embrace new technologies.‚Äù</li> </ul> <h2 id="10-company-specific-knowledge">10. Company-specific Knowledge</h2> <ul> <li>a. NVIDIA‚Äôs mission and values</li> <li>b. NVIDIA‚Äôs products and services</li> <li>c. NVIDIA‚Äôs involvement in deep learning and AI research</li> <li>d. Recent news and updates about the company</li> </ul>]]></content><author><name></name></author><category term="Deep Learning"/><category term="Interview Preparation"/><summary type="html"><![CDATA[A Comprehensive Study Guide for Deep Learning Engineer Interviews at NVIDIA]]></summary></entry><entry><title type="html">Exploring the Double Pendulum: An Interactive Simulation</title><link href="https://dltemple.github.io/thoughts/2023/interactive-double-pendulum/" rel="alternate" type="text/html" title="Exploring the Double Pendulum: An Interactive Simulation"/><published>2023-04-08T00:00:00+00:00</published><updated>2023-04-08T00:00:00+00:00</updated><id>https://dltemple.github.io/thoughts/2023/interactive-double-pendulum</id><content type="html" xml:base="https://dltemple.github.io/thoughts/2023/interactive-double-pendulum/"><![CDATA[<p>The double pendulum, a simple yet fascinating system, has been the subject of study for scientists and mathematicians for centuries. Despite its seemingly simple construction, it exhibits rich and chaotic behavior. In this blog post, we‚Äôll explore the double pendulum, its equations of motion, and an interactive simulation that lets you experience its captivating dynamics.</p> <h2 id="what-is-a-double-pendulum">What is a Double Pendulum?</h2> <p>A double pendulum consists of two pendulums connected end-to-end. It has two degrees of freedom: the angles each pendulum makes with the vertical. This system‚Äôs seemingly simple construction belies its complex, chaotic motion. Small changes in initial conditions can lead to dramatically different outcomes, making the double pendulum an excellent example of a chaotic system.</p> <h2 id="equations-of-motion">Equations of Motion</h2> <p>The equations of motion for the double pendulum are derived from Newton‚Äôs second law or by using the Lagrangian formulation of classical mechanics. The resulting equations are a set of coupled second-order nonlinear differential equations:</p> \[\begin{aligned} \frac{d^2\theta_1}{dt^2} &amp;= \frac{-g(2m_1 + m_2) \sin\theta_1 - m_2g \sin(\theta_1 - 2\theta_2) - 2\sin(\theta_1 - \theta_2)m_2(\omega_2^2 L_2 + \omega_1^2 L_1 \cos(\theta_1 - \theta_2))}{L_1(2m_1 + m_2 - m_2\cos(2\theta_1 - 2\theta_2))} \\ \frac{d^2\theta_2}{dt^2} &amp;= \frac{2\sin(\theta_1 - \theta_2)(\omega_1^2 L_1(m_1 + m_2) + g(m_1 + m_2)\cos\theta_1 + \omega_2^2 L_2 m_2\cos(\theta_1 - \theta_2))}{L_2(2m_1 + m_2 - m_2\cos(2\theta_1 - 2\theta_2))} \end{aligned}\] <p>These equations are challenging to solve analytically. However, we can use numerical methods like the Runge-Kutta method to simulate the double pendulum‚Äôs motion.</p> <h2 id="interactive-simulation">Interactive Simulation</h2> <p>Below is an interactive simulation of a double pendulum. The simulation allows you to adjust parameters such as mass, gravity, time step, and damping. You can also control the fade duration of the motion trails.</p> <link rel="stylesheet" href="/assets/css/double_pendulum_simulation.css"/> <html lang="en"> <head> <meta charset="UTF-8"/> <meta name="viewport" content="width=device-width, initial-scale=1.0"/> <title>Double Pendulum Simulation</title> </head> <body> <div id="simulation-and-plots"> <div id="double-pendulum-container"> <div id="double-pendulum-plot"></div> <div class="buttons"> <button id="start-button">Start</button> <button id="stop-button">Stop</button> </div> <div class="params-container"> <div class="param-group"> <label for="m1">Mass 1:</label> <input type="number" id="m1" step="0.1" value="1"/> </div> <div class="param-group"> <label for="m2">Mass 2:</label> <input type="number" id="m2" step="0.1" value="1"/> </div> <div class="param-group"> <label for="fade-duration">Fade duration (seconds):</label> <input type="range" id="fade-duration" name="fade-duration" min="0" max="10" step="0.1" value="1"/> </div> <div class="param-group"> <label for="gravity">Gravity:</label> <input type="number" id="gravity" value="9.81" step="0.1" min="0"/> </div> <div class="param-group"> <label for="time-step">Time step:</label> <input type="number" id="time-step" value="0.01" step="0.001" min="0"/> </div> <div class="param-group"> <label for="steps">Steps:</label> <input type="number" id="steps" value="1000" step="10" min="0"/> </div> <div class="param-group"> <label for="damping">Damping:</label> <input type="number" id="damping" value="0.0001" step="0.01" min="0" max="1"/> </div> </div> </div> <div id="simulation-container"> <div id="state-plot"></div> <div id="deriv-plot"></div> </div> </div> <script src="/assets/js/double_pendulum.js"></script> </body> </html> <div style="clear:both;"></div> <p>To start the simulation, click the ‚ÄúStart‚Äù button. You can pause it at any time by clicking ‚ÄúStop.‚Äù Adjust the parameters using the input fields and sliders, and watch how the double pendulum‚Äôs motion changes.</p> <h2 id="what-makes-the-double-pendulum-special">What Makes the Double Pendulum Special?</h2> <p>The double pendulum is special for its ability to display a wide range of behaviors, from simple oscillations to chaotic motion. This sensitivity to initial conditions and its unpredictable nature make the double pendulum a popular subject of study in classical mechanics and chaos theory.</p> <p>The double pendulum also demonstrates the power of computational methods in solving complex problems. By using numerical integration techniques, we can explore the motion of the double pendulum without needing an exact analytical solution.</p> <h2 id="lyapunov-exponent">Lyapunov Exponent</h2> <p>The Lyapunov exponent is a measure of the sensitivity of a dynamical system to its initial conditions. It quantifies the average divergence or convergence of trajectories in the system‚Äôs phase space. A positive Lyapunov exponent indicates a chaotic system, such as the double pendulum. By calculating the Lyapunov exponent for a range of initial conditions, we can gain a better understanding of the double pendulum‚Äôs chaotic behavior and the regions in its phase space where chaos is more likely to occur.</p> <h2 id="poincar√©-section">Poincar√© Section</h2> <p>A Poincar√© section is a valuable tool in the analysis of dynamical systems, providing insights into their behavior and structure. In the context of the double pendulum, the Poincar√© section reveals patterns in the system‚Äôs phase space that may not be immediately apparent from direct observations of the pendulum‚Äôs motion.</p> <p>To construct the Poincar√© section for the double pendulum, we plot the angular velocities (omega1 and omega2) each time the angle of the first pendulum (theta1) crosses zero. In other words, we are capturing snapshots of the system‚Äôs state at regular intervals in its trajectory through phase space. These points are then plotted on a scatter plot, with the horizontal axis representing the angular velocity of pendulum 1 (omega1) and the vertical axis representing the angular velocity of pendulum 2 (omega2).</p> <div> <iframe src="/assets/html/double_pendulum_poincare.html" width="1200" height="800" frameborder="0" style="border:none; overflow:hidden;"></iframe> </div> <p>Examining the resulting Poincar√© section can offer insights into the system‚Äôs behavior. For instance, the presence of distinct clusters or patterns may suggest underlying regularities or periodicities in the double pendulum‚Äôs motion. Conversely, a more scattered or random distribution of points may indicate chaotic behavior.</p> <p>By studying the Poincar√© section, we can deepen our understanding of the double pendulum‚Äôs dynamics and gain a more nuanced appreciation for the complex interplay between its various components.</p> <h2 id="interpreting-the-double-pendulum-heatmap">Interpreting the Double Pendulum Heatmap</h2> <p>In this section, we will discuss how to interpret the heatmap of double pendulum end positions and extract useful insights from it.</p> <p>The heatmap represents the final x and y positions of the second mass of the double pendulum system based on various initial conditions. Each point on the heatmap corresponds to a specific set of initial conditions: initial angles ( Theta1 and Theta2) and initial angular velocities (Omega1 and Omega2). The color of each point represents the initial angle of the first pendulum, Theta1.</p> <div> <iframe src="/assets/html/double_pendulum_heatmap.html" width="1000" height="700" frameborder="0" style="border:none; overflow:hidden;"></iframe> </div> <h3 id="understanding-the-heatmap">Understanding the Heatmap</h3> <p>To interpret the heatmap, keep in mind that the double pendulum is a chaotic system. This means that even small changes in the initial conditions can lead to drastically different end positions. In the heatmap, you can observe that the points are spread across a wide range of x and y positions, indicating the chaotic behavior of the system.</p> <p>As you hover over each point, you can see the exact initial conditions (Theta1, Theta2, Omega1, and Omega2) that led to the respective end positions. You can also observe how the color of each point changes with varying initial angles of the first pendulum, providing a visual cue to understand the relationship between the initial conditions and the end positions.</p> <h3 id="useful-takeaways">Useful Takeaways</h3> <ol> <li>Chaotic behavior: The heatmap highlights the inherent chaotic behavior of the double pendulum system. The end positions are scattered across the plot, illustrating the unpredictability and sensitivity to initial conditions.</li> <li>Initial conditions impact: The variation in color emphasizes the influence of initial conditions, especially the initial angle of the first pendulum, on the end positions. Observing how colors cluster or disperse can give you an idea of how different initial conditions affect the system‚Äôs behavior.</li> <li>Areas of interest: By examining the heatmap, you may identify areas with denser or sparser concentrations of points. Denser areas indicate that several different initial conditions led to similar end positions, while sparser areas suggest that fewer initial conditions resulted in those particular end positions. Analyzing these areas can provide valuable insights into the double pendulum‚Äôs behavior under certain conditions. In conclusion, the heatmap is a powerful tool for visualizing the double pendulum system‚Äôs chaotic behavior and understanding the impact of initial conditions on its dynamics. By carefully analyzing the heatmap, you can gain valuable insights into the double pendulum‚Äôs motion and the fascinating complexity of this seemingly simple mechanical system.</li> </ol> <h2 id="machine-learning-for-predicting-double-pendulum-motion">Machine Learning for Predicting Double Pendulum Motion</h2> <p>Machine learning techniques can be applied to predict the motion of the double pendulum, especially for short time horizons. Using data generated from numerical simulations, we can train a neural network or other machine learning models to learn the underlying dynamics of the double pendulum. This approach might not provide long-term accurate predictions due to the chaotic nature of the system, but it can offer insights into the short-term behavior of the double pendulum and potentially improve the efficiency of numerical simulations.</p> <h2 id="analyzing-double-pendulum-data">Analyzing Double Pendulum Data</h2> <p>Data science techniques can be applied to analyze the motion data generated by the double pendulum simulations. By visualizing and exploring the data, we can identify patterns and relationships between the system‚Äôs parameters and its resulting behavior. For example, we can use clustering algorithms to group similar motion patterns or apply dimensionality reduction techniques like principal component analysis (PCA) to identify the most significant factors influencing the double pendulum‚Äôs motion.</p> <h2 id="conclusion">Conclusion</h2> <p>The double pendulum is a captivating system that showcases the complexity that can arise from simple mechanical constructions. Its chaotic motion has inspired numerous research efforts and applications in various fields, from physics to engineering, machine learning, and data science.</p> <p>By exploring the double pendulum‚Äôs motion through interactive simulations, calculating its Lyapunov exponent, applying machine learning models for prediction, and analyzing the generated data, we can gain a deeper appreciation for the intricacies of classical mechanics and the beauty of chaotic systems.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[The double pendulum, a simple yet fascinating system, has been the subject of study for scientists and mathematicians for centuries. Despite its seemingly simple construction, it exhibits rich and chaotic behavior. In this blog post, we‚Äôll explore the double pendulum, its equations of motion, and an interactive simulation that lets you experience its captivating dynamics.]]></summary></entry><entry><title type="html">Visualising Activation Functions in Neural Networks</title><link href="https://dltemple.github.io/thoughts/2023/activation-functions/" rel="alternate" type="text/html" title="Visualising Activation Functions in Neural Networks"/><published>2023-04-04T00:00:00+00:00</published><updated>2023-04-04T00:00:00+00:00</updated><id>https://dltemple.github.io/thoughts/2023/activation-functions</id><content type="html" xml:base="https://dltemple.github.io/thoughts/2023/activation-functions/"><![CDATA[<div class="container"> <div class="activation-functions"> <div class="activation-function"> <h2>Sigmoid</h2> <div id="sigmoid-plot" class="interactive-plot"></div> <div class="metadata"> <p> The Sigmoid function maps input values to the range (0, 1). It's commonly used in binary classification tasks. </p> </div> </div> <div class="activation-function"> <h2>ReLU</h2> <div id="relu-plot" class="interactive-plot"></div> </div> <div class="activation-function"> <h2>Tanh</h2> <div id="tanh-plot" class="interactive-plot"></div> </div> <div class="activation-function"> <h2>Leaky ReLU</h2> <div id="leaky-relu-plot" class="interactive-plot"></div> </div> <div class="activation-function"> <h2>ELU</h2> <div id="elu-plot" class="interactive-plot"></div> </div> <div class="activation-function"> <h2>Swish</h2> <div id="swish-plot" class="interactive-plot"></div> </div> </div> </div>]]></content><author><name>Dwight Temple</name></author><category term="deep learning"/><category term="machine learning"/><category term="deep learning"/><category term="activation function"/><summary type="html"><![CDATA[Using D3, this post visually explores activation functions, a fundamental component of neural networks.]]></summary></entry><entry><title type="html">Megaman-X with Reinforcement Learning</title><link href="https://dltemple.github.io/thoughts/2023/megaman-rl/" rel="alternate" type="text/html" title="Megaman-X with Reinforcement Learning"/><published>2023-02-11T01:00:00+00:00</published><updated>2023-02-11T01:00:00+00:00</updated><id>https://dltemple.github.io/thoughts/2023/megaman-rl</id><content type="html" xml:base="https://dltemple.github.io/thoughts/2023/megaman-rl/"><![CDATA[<p>In many fields of study, state-space-systems are a powerful and tool used to better predict and understand dynamical systems. Kalman, after whom the Kalman Filter is named, derived a steady-state solution for a Gaussian system.</p>]]></content><author><name></name></author><category term="ramblings"/><summary type="html"><![CDATA[Training a RL agent to play SNES Megaman-X]]></summary></entry><entry><title type="html">Radar Target Tracking using Tensorflow</title><link href="https://dltemple.github.io/thoughts/2022/kalman-filter-radar-tensoflow/" rel="alternate" type="text/html" title="Radar Target Tracking using Tensorflow"/><published>2022-09-25T01:00:00+00:00</published><updated>2022-09-25T01:00:00+00:00</updated><id>https://dltemple.github.io/thoughts/2022/kalman-filter-radar-tensoflow</id><content type="html" xml:base="https://dltemple.github.io/thoughts/2022/kalman-filter-radar-tensoflow/"><![CDATA[<p>In many fields of study, state-space-systems are a powerful and tool used to better predict and understand dynamical systems. Kalman, after whom the Kalman Filter is named, derived a steady-state solution for a Gaussian system.</p> <p>This technique can additionally be applied to dynamic systems with:</p> <ul> <li>various observation types (RADAR, LIDAR, optical, etc.)</li> <li>underlying state transition models (ballistic, linear, turning, jerking)</li> <li>systems with known control input (rocket with maneuvers, externally applied forces)</li> </ul> <p>One of the incumberances with effectively using a Kalman derived filter is the need to define:</p> <ul> <li>state transition matrix</li> <li>observation matrix</li> <li>process gain</li> <li>observation gain</li> </ul> <p>These parameters dictate how confident one is in the underlying systems‚Äô dynamics as well as the sensors‚Äô noise characteristics. I.E. how well does our sensor capture the state of the object we are observing?</p> <h2 id="the-kalman-filter">The Kalman Filter</h2> <p>The following steps are for the <strong><em>prediction</em></strong> portion of the filter</p> \[{\begin{align*} \mathbf{x}_{k+1}^{(P)} &amp;= A \mathbf{x}_k + B {a_k}\\ P_{k+1}^{(P)} &amp;= A P_k A^T + Q_k^{(r_s)} \end{align*}}\] <p>The current state at time \(k\), is represented by \(\mathbf{X}_{k}\)</p> <p>For our application, a 12-state Kalman filter for position, velocity, acceleration, and jerk of a 3-D body is</p> \[\mathbf{x} = [p_i \ p_j \ p_k \ v_i \ v_j \ v_k \ a_i \ a_j \ a_k \ j_i \ j_j \ j_k]\] <p>Additionally, the state-transition matrix, \(\mathbf{F_k}\) is the following and is described from <a href="https://www.researchgate.net/publication/3002819_A_jerk_model_to_tracking_highly_maneuvering_targets">THIS PAPER</a></p> \[\mathbf{F_k} = \begin{pmatrix} 1&amp; \Delta T &amp;\Delta T^2 &amp;p_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 1 &amp; \Delta T &amp;q_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 1 &amp;r_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;s_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;1 &amp;\Delta T &amp;\Delta T^2 &amp;p_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;1 &amp;\Delta T &amp;q_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;r_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;s_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;\Delta T &amp;\Delta T^2 &amp;p_1 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;\Delta T &amp;q_1 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;r_1 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;s_1 \end{pmatrix}\] <h2 id="lets-set-up-the-frame-of-reference-for-a-3-dimensional-position-and-velocity-tracker">Let‚Äôs set up the frame of reference for a 3-Dimensional Position and Velocity Tracker</h2> <h3 id="our-sensor">Our sensor</h3> <p>We‚Äôre going to be using a radar to track our ballistic object in this example</p> \[z_{radar} = \begin{pmatrix} \rho \\ \theta \\ \phi \end{pmatrix}\] <p>\(\rho\) and \(\theta\) and \(\phi\) are the spherical coordinate representatinos of: range, azimuth, and elevation (all relative to the sensor)</p> <p>For this example, we‚Äôll also need to define our observation noise. That is, the noise in the measurement uncertainty for each component.</p> <p>Let‚Äôs let \(\sigma_{\rho} = 1\) meters and \(\sigma_{\theta} = 0.0015\) radians \(\sigma_{\phi} = 0.0015\) radians</p> <p>These terms are the diagonal of our <em>observation noise covariance</em></p> \[R_t = \begin{pmatrix} \sigma^2 &amp;0 &amp;0 \\ 0 &amp; \theta^2 &amp;0 \\ 0 &amp; 0 &amp; \phi^2 \end{pmatrix}\] <p>This is cool, but it introduces a problem to solve.</p> <p>We are taking measurements os position only in range and angles, yet our system state \(\mathbf{X_k}\) is in Earth Cenetered Earth Fixedd (ECEF) coordinates</p> <p>We‚Äôve got to address this by converting spherical coordinates to cartesian coordinates.</p> <p>The basic transformation from spherical to Cartesian is:</p> \[\begin{bmatrix} x\\ y\\ z \end{bmatrix} = \begin{bmatrix} \rho *cos \phi *cos \theta \\ \rho *cos \phi * sin \theta \\ \rho *sin \phi \end{bmatrix}\] <p>But this introduces predicaments, and those are the measurement uncertainties defined in \(\mathbf{R_t}\)</p> <p>Long story short.. <a href="https://hal.archives-ouvertes.fr/hal-01081009/document">A Robust Converted Measurement Kalman Filter for Target Tracking</a> derives a method to account for these uncertainties in the coordinate converstion. GREAT! we‚Äôre almost there.</p> <p>Our resulting Python code to produce this conversion is below. The latex for this would have been a bit too intense for this post.</p> <p>For reference.. R = range, A = azimuth, E = elevation (measurements from radar)</p> <p>Rt is the observation covariance noise matrix, \(\mathbf{R_t}\)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    R2 = np.square(R)
    CE = np.cos(E)
    C2E = np.cos(2 * E)

    CA = np.cos(A)
    C2A = np.cos(2 * A)

    SE = np.sin(E)
    S2E = np.sin(2 * E)

    SA = np.sin(A)
    S2A = np.sin(2 * A)

    CA2, SA2, CE2, SE2 = map(np.square, [CA, SA, CE, SE])

    sr, sb, se = [np.sqrt(Rt[:, idx, idx, npna]) for idx in range(3)]

    sr2, se2, sb2 = map(np.square, [sr, se, sb])

    le = np.exp(-se2 / 2)
    lep = np.power(le, 4)
    lB = np.exp(-sb2 / 2)
    lBp = np.power(lB, 4)

    le2 = np.square(le)
    lB2 = np.square(lB)

    R2sr2 = R2 + sr2

    Rxx = -lB2 * le2 * R2 * CA2 * CE2 + 0.25 * R2sr2 * (1 + lBp * C2A) * (1 + lep * C2E)

    Ryy = -lB2 * le2 * R2 * SA2 * CE2 + 0.25 * R2sr2 * (1 - lBp * C2A) * (1 + lep * C2E)

    Rzz = -le2 * R2 * SE2 + 0.5 * (R2 + sr2) * (1 - lep * C2E)

    Rxy = -lB2 * le2 * R2 * SA * CA * CE2 + 0.25 * R2sr2 * lBp * S2A * (1 + lep * C2E)

    Rxz = -lB * le2 * R2 * CA * SE * CE + 0.5 * R2sr2 * lB * lep * CA * S2E

    Ryz = -lB * le2 * R2 * SA * SE * CE + 0.5 * R2sr2 * lB * lep * SA * S2E

    return npc([npc([Rxx[:, :, npna], Rxy[:, :, npna], Rxz[:, :, npna]], axis=2),
                npc([Rxy[:, :, npna], Ryy[:, :, npna], Ryz[:, :, npna]], axis=2),
                npc([Rxz[:, :, npna], Ryz[:, :, npna], Rzz[:, :, npna]], axis=2)],
               axis=1) '''
</code></pre></div></div> \[\begin{align*} K_k &amp;= P_k^{(P)} H^T{\left (H P_k^{(P)} H^T + Q_k^{(R_t)} \right)}^{-1}\\ {\mathbf{x}_k} &amp;= (I - K_k H) \mathbf{x}_k^{(P)} + K_k {z_k}\\ {P_k} &amp;= (I - K_k H) P_k^{(P)} \end{align*}\] <p>For optical tracking, we only have 2 Dimensional observations in aziumth and elevation, but no range information. As a result, we are very certain of position in angular space, but have high uncertainty in range.</p> <p>For RADAR tracking, we have excellent range information and noisy (er) azimuth and elevation measurements based on the sensors‚Äô pointing status. As a result, we can be very confident in range and range-rate measurements, but are less confident in angular space.</p>]]></content><author><name></name></author><category term="ramblings"/><summary type="html"><![CDATA[Training a Kalman Filter using Tensorflow P1]]></summary></entry><entry><title type="html">MacroFactor - Data Driven and Mentally Freeing</title><link href="https://dltemple.github.io/thoughts/2022/macro-factor-is-the-best/" rel="alternate" type="text/html" title="MacroFactor - Data Driven and Mentally Freeing"/><published>2022-09-23T01:00:00+00:00</published><updated>2022-09-23T01:00:00+00:00</updated><id>https://dltemple.github.io/thoughts/2022/macro-factor-is-the-best</id><content type="html" xml:base="https://dltemple.github.io/thoughts/2022/macro-factor-is-the-best/"><![CDATA[<p>If there‚Äôs one thing about me anyone knows, it‚Äôs that I‚Äôm frugal to the point of being <em>_slightly</em> off-putting_.</p> <p>Appetizers, non-essential fashion, random gadgets, and items that everyone deems as ‚Äúmust-have‚Äù completely pass me by.</p> <p>Apps (applications, like the kind on your phone) are by-and-far the easiest for me to pass.</p> <p>Why would I buy an app to do something I can do myself, figure out how to do myself, or maybe I just don‚Äôt need to use?</p> <p>That being said; I‚Äôve been a fitness and health and diet junkie for as long as I can remember. I‚Äôm that guy who has had 3+ year streaks on MyFitnessPal. You don‚Äôt want to compete against me in a Close-your-rings challenge with the Apple Watch. I have notebooks and spreadsheets and Evernotes laden with years of workouts, progression plans, and aspirations.</p> <p>I‚Äôve always been increasingly skeptical of pay-for-service fitness apps because the typical use-case is preying on peoples‚Äô insecurities in exchange for a promise of faster, better, and to be honest‚Ä¶ lackluster results.</p> <hr/> <p>Enter <a href="https://www.strongerbyscience.com/">Stronger By Science</a> -</p> <p><a href="http://gregnuckols.com/">Greg Nuckols</a> and <a href="https://www.strongerbyscience.com/coaching/eric-trexler/">Eric Trexler</a> (two guest co-hosts on a globally distributed, audience captivating, strength science <a href="https://www.strongerbyscience.com/podcast/">podcast</a>) were also similarly frustrated with the fitness app landscape.</p> <p>Instead of abstaining from participating in the ecosystem, they decided to craft a potent team and deliver to market the most superior diet-assistance application.</p> <p>Of course, I was equally hesitant about falling for the same old song-and-dance. However, one year after the launch of <a href="https://www.strongerbyscience.com/macrofactor/">MacroFactor</a>, and after listening to <strong>¬ª</strong> 200 podcasts from them, I decided to purchase and evaluate the new-fangled hubbaboloo.</p> <hr/> <p>Being someone in the machine learning and data science field, I can‚Äôt help but be overly scrupulous with what goes into the backend of some basic apps. Greg and Eric are smart guys, and they are equally as scrupulous. As a result, they have delivered something that is scientifically sound, dynamic, and user-friendly in the truest sense.</p> <p>One of the simplest sounding, and easiest to compute improperly metrics is one‚Äôs total daily energy expenditure (TDEE).</p> <p>On many online calculators, you can get a range of estimates by parametrizing your age, weight, sex, body-composition, and activity level estimates. You‚Äôll quickly discover that these estimates vary wildly from (for example) 1,750 to 2,500 calories per day required for weight maintenance. Of course, that range is unwieldly large and can create confusion about how much and of what to consume for optimal body-composition results.</p> <p>MacroFactor does something novel and data-driven about this and I‚Äôm obsessed.</p> <p>Unlike other apps, it doesn‚Äôt add in estimates for all your steps, entered workouts, and other estimated expenditures because there is simply too much variance to account for between individuals. To complicate the picture further, non-exercise activity thermogenesis (NEAT), basically how much fidgeting and wiggling and non-planned output you perform can range from 200 ‚Äì 1,000 calories per day.</p> <p>To resolve these many variances, MacroFactor <strong><em>appears</em></strong> to use some exponential smoothing and attempts to evaluate your estimated TDEE based on accurate energy consumption and your daily weigh-in trends.</p> <hr/> <p>For those who are interested‚Ä¶ here‚Äôs the formulas and initial value parameters. -</p> <p>\begin{eqnarray} S_t &amp; = &amp; \alpha y_t + (1 - \alpha)(S_{t-1} + b_{t-1}) &amp; &amp; 0 \le \alpha \le 1 <br/> \end{eqnarray}</p> <p>\begin{eqnarray} b_t &amp; = &amp; \gamma(S_t - S_{t-1}) + (1 - \gamma) b_{t-1} &amp; &amp; 0 \le \gamma \le 1 \end{eqnarray}</p> <p>\begin{eqnarray} b_1 &amp; = &amp; \frac{1}{3} \left[ (y_2 - y_1) + (y_3 - y_2) + (y_4 - y_3) \right] <br/> \end{eqnarray}</p> <p>\(\alpha\) and \(\gamma\) are tunable parameters used in determining how much historical information and how much current informatino to keep and incorporate, respectively.</p> <p>\(\alpha\) dictates how much of the current observation to add to the projected values \(\gamma\) is a term used to define how much of the historically trend to incorporate.</p> <p>In general‚Ä¶ The larger \(\alpha\), the more emphasis is placed on new updates. the larger \(\gamma\), the ‚Äúheavier‚Äù the historical trend is considered.</p> <p>Using Equation (3), one can kick-start the smoothing process. this requires (4) initial observations. In this case, the observations are weight.</p> <h2 id="its-beautiful-its-dynamic-it-tells-the-truth">It‚Äôs beautiful. It‚Äôs dynamic. It tells the truth.</h2> <p>If the user is consistent (and honest) with energy consumption and weighing daily under identical circumstances, it appears to be the best true estimate of expenditure I‚Äôve ever observed.</p> <p>As your weight trend and eating patterns are established, the smoothing formula can be initialized, and the fun begins.</p> <p>If your weight being trending up, say, 0.5 pounds per week, and you‚Äôre eating ‚Äúat‚Äù your supposed maintenance calories required. The TDEE estimation dynamically adjusts to fit the supposition that you (the user) are actually in a daily 250 calorie surplus. This means that your TDEE is actually 250 calories LOWER than what you initially suspected. The beauty is, now you can take action, lower your calories, and adjust without making radical changes abruptly.</p> <p>Well, one might say, that sounds really basic and doesn‚Äôt require anything other than pencil, paper, and a calculator if you can‚Äôt do basic math in your head. Why would someone pay for this?</p> <p>Because it‚Äôs <strong>COOL</strong> and it‚Äôs <strong>PRETTY</strong></p> <p>Let‚Äôs think of another practical scenario.</p> <p>You‚Äôre targeting weight maintenance, and you‚Äôve been holding steady, but one night you decide to have most of a bottle of soy sauce (please don‚Äôt do this). Because of physiological necessity to balance your blood-ion and intracellular ratios, you retain significantly more water.</p> <p>As a result, your weight increases 5 pounds overnight. This is the beauty in using some exponential smoothing method. There is a time-weighted decay factor that ‚Äúremembers‚Äù and ‚Äúforgets‚Äù recent and forgone events (fluctuations in weight). The app won‚Äôt see a 5-pound overnight gain and assume you were in a 17,500 (5 * 3,500) calorie surplus and gained that much body tissue. Most likely, your weight will adjust down to baseline over the course of two days as your body sheds the excess water and you return to baseline. The smoothing model captures the trend; as a result, your TDEE estimate remains on track for the maintenance calories you‚Äôve been consuming.</p> <hr/> <p>What does all this mean and why does it matter? -</p> <p>Mental health; it‚Äôs all about mental health</p> <p>For those who have been through periods of restriction, body recomposition, or intentional weight gain, it is a WILD rollercoaster. Unless you have the diligence and a Spock-like demeanor, emotions happen, and you overreact.</p> <p>These overreactions can be: days of sever-restriction to compensate for your soy sauce mistake, binging on too many donuts to accelerate your weight-gain endeavor, or simply being unsure about what to do on a daily basis.</p> <p>MacroFactor attempts to not penalize the user harshly through wild compensations in calories or berating you for being over your target for the day. As stated in the beginning, it is a diet assistance. If you‚Äôve ever seen Matilda, MacroFactor is Ms. Honey and (every other app) is the Trunchbull.</p> <p>As someone who‚Äôs been a lifelong skeptic, I‚Äôve given it a shot and I think you should likely try it too. It‚Äôs been relieving and comforting. Nonetheless, you‚Äôre in the good hands of two guest cohosts to a globally distributed podcast.</p>]]></content><author><name></name></author><category term="ramblings"/><summary type="html"><![CDATA[A newer and better way to track TDEE]]></summary></entry><entry><title type="html">Podcasts Ruined my Life</title><link href="https://dltemple.github.io/thoughts/2022/podcasts-ruined-my-life/" rel="alternate" type="text/html" title="Podcasts Ruined my Life"/><published>2022-09-12T18:40:16+00:00</published><updated>2022-09-12T18:40:16+00:00</updated><id>https://dltemple.github.io/thoughts/2022/podcasts-ruined-my-life</id><content type="html" xml:base="https://dltemple.github.io/thoughts/2022/podcasts-ruined-my-life/"><![CDATA[<h1>Listening to Lex Fridman, Sam Parr, Andrew Huberman, and Chase Chewning slowly ruined my life. Here‚Äôs how I fixed it.</h1> <p>Optimization, entrepreneurship, emotionalism, connectedness, and the endless pursuit of excellence: each of these tenants are fundamental to me and probably you too!</p> <p>To stumble upon these guys is a Godsend. The words they and their guests breathe can dramatically shift your perspective on numerous topics and each host does so with their own distinct cadence, sound, and demeanor.</p> <p><strong>Lex:</strong> melding of scientific rigor, compassion, empathy, and child-like curiosity and hope.</p> <p><strong>Sam:</strong> happy-go-lucky, yet driven and passionate entrepreneur seeking opportunity</p> <p><strong>Andrew:</strong> insight into the mind of a practitioner, proclaimer, and professor of all things cutting edge and how to most potently apply to your life with a little bit of punk rocker and tumultuous underdog upbringing.</p> <p><strong>Chase:</strong> endless exploration, experimentation, and pursuit of everything self-care, self-actualization, and focusing on the truly important aspects of living a fulfilled life</p> <p>You‚Äôve probably experienced what I have.</p> <p>Thoughtfully preparing your morning coffee while eagerly awaiting the podcast to download for your run, commute, or existence.</p> <p>You did it! You hacked the system.</p> <p>You transformed into that idealized dream of a person who enjoys long cardio, lifting, or just not despising your commute. To top it off, you get to factually saturate every wrinkle in your brain. Your brain that was convinced it was becoming increasingly attuned to your weaknesses, improving them, and bursting through next obstacles. You‚Äôre going to conquer the world!</p> <p>Weeks, months, years pass, and you‚Äôre a bit better at whatever activity you‚Äôve chosen. You‚Äôve probably burned through numerous pairs of shoes and purchased some more secure headphones for your runs to ensure you don‚Äôt miss a single utterance of a Fridman phrase. You‚Äôre now getting 5-10 minutes of sunlight after waking up to optimize your circadian rhythm. You prolong your caffeine intake, fast for 16 hours, don‚Äôt eat within 2 hours of sleep, keep your eyes open for arbitrage opportunities in the market‚Ä¶ the list continues indefinitely.</p> <p>Life is great! I mean, how can it not be? You‚Äôve been exposed to philosophy, cutting-edge genomics, hormonal optimization, copywriting, micro dosing psilocybin for and its anxiolytic effects, dietary and training approaches for longevity, how to best market to your audience, how to create an audience, the importance of sleep, cryptocurrency and all its promise, flaws, schemes, and scams.</p> <ul> <li>How to be focused</li> <li>How to start your morning</li> <li>What to eat</li> <li>When to sleep</li> <li>When to wake up</li> <li>What temperature you should sleep at</li> <li>Which muscles to target</li> <li>Which compound lifts are most potent</li> <li>How long should I be able to dead-hang for</li> <li>How to bulletproof your knees</li> <li>How to bulletproof your coffee</li> </ul> <p><strong>‚Ä¶</strong></p> <p>I think you get it</p> <p>Seemingly, out of nowhere, and yet <em>slowly</em>, you began to feel uneasy. Your finely tuned routines and habits were fine. You hadn‚Äôt abruptly changed anything. You‚Äôd just carefully sewn and injected most of what you‚Äôd been learning from your ‚Äúpeers‚Äù into your cramped daily routine. Life was good though if you were consuming more high-density information.</p> <p>You‚Äôd queue as many podcasts as possible to listen to throughout the day. You couldn‚Äôt imagine walking the dog, going to the mailbox, corralling yourself to the kitchen, stumbling down the hall, without one or both of your headphones playing someone‚Äôs melodious facts and voice into your skull.</p> <p>Your mind was perpetually churning with the incessant life optimization schemas. Schemas that if you didn‚Äôt follow, your life would return to shambles. You‚Äôd be in tattered rags, unfulfilled, non-optimal‚Ä¶ anything but great and definitely not excellent.</p> <p>You‚Äôd be eternal confused and pursuing everything.</p> <p>You feel like your addicted to podcasts and information curation in general. But that‚Äôs not possible, is it? Addictions are for people with problems. Addictions are detrimental. How can learning to be a better person 100% of the time be an addiction? You rationalize, move on with your day, and silence the uncomfortable itch that maybe something isn‚Äôt quite right.</p> <p>For months, you failed to pinpoint the source of the muted yet screaming voice emanating from somewhere within as to why EXACTLY you aren‚Äôt as content as you should be. You‚Äôve got so much going right for you. Where is this discomfort coming from? Why can‚Äôt I quite my mind anymore and just relax?</p> <p>Because it isn‚Äôt exactly coming from within you in the first place.</p> <p>It is reinforced day-in and day-out through recognition of the short fallings in your life and the life that you are supposed to be executing according to all the brilliant information you intentionally consume.</p> <p>After all, how can you be presented with the truth and then actively turn away from it? How could you viscerally connect with these phenoms of humans only to disregard their evidence-based practices that will help you have a better life?</p> <p>Lex, Sam, Chase, and Andrew would never recommend this all-or-nothing approach. Of course, they don‚Äôt expect perfection or disciple-like compliance with their recommendations, thoughts, and opinions.</p> <p>So, what can you do about it? How could you possibly escape the gravitron wheel of self-betterment, performance optimization, mental clarity, entrepreneurship, while trying to lead a fulfilled and meaningful life?</p> <p>It‚Äôs incredibly simple, but it is incredibly uncomfortable.</p> <p>Be with yourself. Be with your thoughts. Be someone who thinks deeply without the incessant external stimulus of thought-leaders.</p> <p>Instead of listening to these people day-in and day-out, pause between their words. Let them simmer. Much like any stressor, lifting weights, learning a foreign language, getting better at a new job‚Ä¶ it‚Äôs tough. It requires bouts of resistance and bouts of recovery. You shouldn‚Äôt treat your mind any differently. It needs deep rest. It needs moments of solitude to refine the tremendous stimulus you subject it to.</p> <p>Give it a try. Let yourself get lost within your own thoughts. Let your mind wonder as you wander.</p> <p>Something that I can guarantee is that you will be astounded by the mental clarification that occurs when you begin to pay attention to the spaces in between words of wisdom. When you let them crystalize and intentionally thread them into your own thought patterns instead of conforming to someone else‚Äôs.</p> <h1 id="be-you">Be you.</h1>]]></content><author><name></name></author><category term="ramblings"/><summary type="html"><![CDATA[Something about my mind]]></summary></entry></feed>