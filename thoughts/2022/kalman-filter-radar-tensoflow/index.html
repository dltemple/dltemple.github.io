<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Radar Target Tracking using Tensorflow | DWGHT</title> <meta name="author" content="Dwight L. Temple"> <meta name="description" content="Training a Kalman Filter using Tensorflow P1"> <meta name="keywords" content="dwight temple, machine learning, exoanalytic solutions,"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://dltemple.github.io/thoughts/2022/kalman-filter-radar-tensoflow/"> <link rel="stylesheet" href="/assets/css/custom.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="https://cdn.plot.ly/plotly-latest.min.js"></script> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">DWGHT</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">thoughts</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/photos/">photos</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Radar Target Tracking using Tensorflow</h1> <p class="post-meta">September 25, 2022</p> <p class="post-tags"> <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>   ·   <a href="/blog/category/ramblings"> <i class="fas fa-tag fa-sm"></i> ramblings</a>   </p> </header> <article class="post-content"> <p>In many fields of study, state-space-systems are a powerful and tool used to better predict and understand dynamical systems. Kalman, after whom the Kalman Filter is named, derived a steady-state solution for a Gaussian system.</p> <p>This technique can additionally be applied to dynamic systems with:</p> <ul> <li>various observation types (RADAR, LIDAR, optical, etc.)</li> <li>underlying state transition models (ballistic, linear, turning, jerking)</li> <li>systems with known control input (rocket with maneuvers, externally applied forces)</li> </ul> <p>One of the incumberances with effectively using a Kalman derived filter is the need to define:</p> <ul> <li>state transition matrix</li> <li>observation matrix</li> <li>process gain</li> <li>observation gain</li> </ul> <p>These parameters dictate how confident one is in the underlying systems’ dynamics as well as the sensors’ noise characteristics. I.E. how well does our sensor capture the state of the object we are observing?</p> <h2 id="the-kalman-filter">The Kalman Filter</h2> <p>The following steps are for the <strong><em>prediction</em></strong> portion of the filter</p> \[{\begin{align*} \mathbf{x}_{k+1}^{(P)} &amp;= A \mathbf{x}_k + B {a_k}\\ P_{k+1}^{(P)} &amp;= A P_k A^T + Q_k^{(r_s)} \end{align*}}\] <p>The current state at time \(k\), is represented by \(\mathbf{X}_{k}\)</p> <p>For our application, a 12-state Kalman filter for position, velocity, acceleration, and jerk of a 3-D body is</p> \[\mathbf{x} = [p_i \ p_j \ p_k \ v_i \ v_j \ v_k \ a_i \ a_j \ a_k \ j_i \ j_j \ j_k]\] <p>Additionally, the state-transition matrix, \(\mathbf{F_k}\) is the following and is described from <a href="https://www.researchgate.net/publication/3002819_A_jerk_model_to_tracking_highly_maneuvering_targets" rel="external nofollow noopener" target="_blank">THIS PAPER</a></p> \[\mathbf{F_k} = \begin{pmatrix} 1&amp; \Delta T &amp;\Delta T^2 &amp;p_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 1 &amp; \Delta T &amp;q_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 1 &amp;r_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;s_1 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;1 &amp;\Delta T &amp;\Delta T^2 &amp;p_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;1 &amp;\Delta T &amp;q_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;r_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;s_1 &amp;0 &amp;0 &amp;0 &amp;0 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;\Delta T &amp;\Delta T^2 &amp;p_1 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;\Delta T &amp;q_1 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;1 &amp;r_1 \\ 0&amp; 0 &amp; 0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;0 &amp;s_1 \end{pmatrix}\] <h2 id="lets-set-up-the-frame-of-reference-for-a-3-dimensional-position-and-velocity-tracker">Let’s set up the frame of reference for a 3-Dimensional Position and Velocity Tracker</h2> <h3 id="our-sensor">Our sensor</h3> <p>We’re going to be using a radar to track our ballistic object in this example</p> \[z_{radar} = \begin{pmatrix} \rho \\ \theta \\ \phi \end{pmatrix}\] <p>\(\rho\) and \(\theta\) and \(\phi\) are the spherical coordinate representatinos of: range, azimuth, and elevation (all relative to the sensor)</p> <p>For this example, we’ll also need to define our observation noise. That is, the noise in the measurement uncertainty for each component.</p> <p>Let’s let \(\sigma_{\rho} = 1\) meters and \(\sigma_{\theta} = 0.0015\) radians \(\sigma_{\phi} = 0.0015\) radians</p> <p>These terms are the diagonal of our <em>observation noise covariance</em></p> \[R_t = \begin{pmatrix} \sigma^2 &amp;0 &amp;0 \\ 0 &amp; \theta^2 &amp;0 \\ 0 &amp; 0 &amp; \phi^2 \end{pmatrix}\] <p>This is cool, but it introduces a problem to solve.</p> <p>We are taking measurements os position only in range and angles, yet our system state \(\mathbf{X_k}\) is in Earth Cenetered Earth Fixedd (ECEF) coordinates</p> <p>We’ve got to address this by converting spherical coordinates to cartesian coordinates.</p> <p>The basic transformation from spherical to Cartesian is:</p> \[\begin{bmatrix} x\\ y\\ z \end{bmatrix} = \begin{bmatrix} \rho *cos \phi *cos \theta \\ \rho *cos \phi * sin \theta \\ \rho *sin \phi \end{bmatrix}\] <p>But this introduces predicaments, and those are the measurement uncertainties defined in \(\mathbf{R_t}\)</p> <p>Long story short.. <a href="https://hal.archives-ouvertes.fr/hal-01081009/document" rel="external nofollow noopener" target="_blank">A Robust Converted Measurement Kalman Filter for Target Tracking</a> derives a method to account for these uncertainties in the coordinate converstion. GREAT! we’re almost there.</p> <p>Our resulting Python code to produce this conversion is below. The latex for this would have been a bit too intense for this post.</p> <p>For reference.. R = range, A = azimuth, E = elevation (measurements from radar)</p> <p>Rt is the observation covariance noise matrix, \(\mathbf{R_t}\)</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    R2 = np.square(R)
    CE = np.cos(E)
    C2E = np.cos(2 * E)

    CA = np.cos(A)
    C2A = np.cos(2 * A)

    SE = np.sin(E)
    S2E = np.sin(2 * E)

    SA = np.sin(A)
    S2A = np.sin(2 * A)

    CA2, SA2, CE2, SE2 = map(np.square, [CA, SA, CE, SE])

    sr, sb, se = [np.sqrt(Rt[:, idx, idx, npna]) for idx in range(3)]

    sr2, se2, sb2 = map(np.square, [sr, se, sb])

    le = np.exp(-se2 / 2)
    lep = np.power(le, 4)
    lB = np.exp(-sb2 / 2)
    lBp = np.power(lB, 4)

    le2 = np.square(le)
    lB2 = np.square(lB)

    R2sr2 = R2 + sr2

    Rxx = -lB2 * le2 * R2 * CA2 * CE2 + 0.25 * R2sr2 * (1 + lBp * C2A) * (1 + lep * C2E)

    Ryy = -lB2 * le2 * R2 * SA2 * CE2 + 0.25 * R2sr2 * (1 - lBp * C2A) * (1 + lep * C2E)

    Rzz = -le2 * R2 * SE2 + 0.5 * (R2 + sr2) * (1 - lep * C2E)

    Rxy = -lB2 * le2 * R2 * SA * CA * CE2 + 0.25 * R2sr2 * lBp * S2A * (1 + lep * C2E)

    Rxz = -lB * le2 * R2 * CA * SE * CE + 0.5 * R2sr2 * lB * lep * CA * S2E

    Ryz = -lB * le2 * R2 * SA * SE * CE + 0.5 * R2sr2 * lB * lep * SA * S2E

    return npc([npc([Rxx[:, :, npna], Rxy[:, :, npna], Rxz[:, :, npna]], axis=2),
                npc([Rxy[:, :, npna], Ryy[:, :, npna], Ryz[:, :, npna]], axis=2),
                npc([Rxz[:, :, npna], Ryz[:, :, npna], Rzz[:, :, npna]], axis=2)],
               axis=1) '''
</code></pre></div></div> \[\begin{align*} K_k &amp;= P_k^{(P)} H^T{\left (H P_k^{(P)} H^T + Q_k^{(R_t)} \right)}^{-1}\\ {\mathbf{x}_k} &amp;= (I - K_k H) \mathbf{x}_k^{(P)} + K_k {z_k}\\ {P_k} &amp;= (I - K_k H) P_k^{(P)} \end{align*}\] <p>For optical tracking, we only have 2 Dimensional observations in aziumth and elevation, but no range information. As a result, we are very certain of position in angular space, but have high uncertainty in range.</p> <p>For RADAR tracking, we have excellent range information and noisy (er) azimuth and elevation measurements based on the sensors’ pointing status. As a result, we can be very confident in range and range-rate measurements, but are less confident in angular space.</p> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Dwight L. Temple. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>